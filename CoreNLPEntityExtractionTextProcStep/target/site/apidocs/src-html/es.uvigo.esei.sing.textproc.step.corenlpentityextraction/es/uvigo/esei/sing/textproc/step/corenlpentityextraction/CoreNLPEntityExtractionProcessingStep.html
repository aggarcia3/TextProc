<!DOCTYPE HTML>
<html lang="es">
<head>
<!-- Generated by javadoc -->
<title>Source code</title>
<meta name="description" content="source: module: es.uvigo.esei.sing.textproc.step.corenlpentityextraction, package: es.uvigo.esei.sing.textproc.step.corenlpentityextraction, class: CoreNLPEntityExtractionProcessingStep">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../../../../../stylesheet.css" title="Style">
</head>
<body class="source">
<main role="main">
<div class="sourceContainer">
<pre><span class="sourceLineNo">001</span><a id="line.1">// SPDX-License-Identifier: GPL-3.0-or-later</a>
<span class="sourceLineNo">002</span><a id="line.2"></a>
<span class="sourceLineNo">003</span><a id="line.3">package es.uvigo.esei.sing.textproc.step.corenlpentityextraction;</a>
<span class="sourceLineNo">004</span><a id="line.4"></a>
<span class="sourceLineNo">005</span><a id="line.5">import java.io.BufferedReader;</a>
<span class="sourceLineNo">006</span><a id="line.6">import java.io.File;</a>
<span class="sourceLineNo">007</span><a id="line.7">import java.io.FileReader;</a>
<span class="sourceLineNo">008</span><a id="line.8">import java.io.IOException;</a>
<span class="sourceLineNo">009</span><a id="line.9">import java.io.InputStreamReader;</a>
<span class="sourceLineNo">010</span><a id="line.10">import java.io.ObjectOutputStream;</a>
<span class="sourceLineNo">011</span><a id="line.11">import java.io.OutputStream;</a>
<span class="sourceLineNo">012</span><a id="line.12">import java.io.PrintStream;</a>
<span class="sourceLineNo">013</span><a id="line.13">import java.nio.charset.StandardCharsets;</a>
<span class="sourceLineNo">014</span><a id="line.14">import java.nio.file.Files;</a>
<span class="sourceLineNo">015</span><a id="line.15">import java.nio.file.Path;</a>
<span class="sourceLineNo">016</span><a id="line.16">import java.nio.file.StandardCopyOption;</a>
<span class="sourceLineNo">017</span><a id="line.17">import java.nio.file.StandardOpenOption;</a>
<span class="sourceLineNo">018</span><a id="line.18">import java.sql.SQLException;</a>
<span class="sourceLineNo">019</span><a id="line.19">import java.util.AbstractMap.SimpleImmutableEntry;</a>
<span class="sourceLineNo">020</span><a id="line.20">import java.util.ArrayList;</a>
<span class="sourceLineNo">021</span><a id="line.21">import java.util.Arrays;</a>
<span class="sourceLineNo">022</span><a id="line.22">import java.util.Collections;</a>
<span class="sourceLineNo">023</span><a id="line.23">import java.util.HashMap;</a>
<span class="sourceLineNo">024</span><a id="line.24">import java.util.List;</a>
<span class="sourceLineNo">025</span><a id="line.25">import java.util.Map;</a>
<span class="sourceLineNo">026</span><a id="line.26">import java.util.Map.Entry;</a>
<span class="sourceLineNo">027</span><a id="line.27">import java.util.Properties;</a>
<span class="sourceLineNo">028</span><a id="line.28">import java.util.Set;</a>
<span class="sourceLineNo">029</span><a id="line.29">import java.util.concurrent.ExecutionException;</a>
<span class="sourceLineNo">030</span><a id="line.30">import java.util.function.Function;</a>
<span class="sourceLineNo">031</span><a id="line.31"></a>
<span class="sourceLineNo">032</span><a id="line.32">import javax.persistence.PersistenceException;</a>
<span class="sourceLineNo">033</span><a id="line.33"></a>
<span class="sourceLineNo">034</span><a id="line.34">import edu.stanford.nlp.ling.CoreAnnotations.SentencesAnnotation;</a>
<span class="sourceLineNo">035</span><a id="line.35">import edu.stanford.nlp.patterns.DataInstance;</a>
<span class="sourceLineNo">036</span><a id="line.36">import edu.stanford.nlp.patterns.GetPatternsFromDataMultiClass;</a>
<span class="sourceLineNo">037</span><a id="line.37">import edu.stanford.nlp.patterns.PatternFactory;</a>
<span class="sourceLineNo">038</span><a id="line.38">import edu.stanford.nlp.patterns.surface.SurfacePattern;</a>
<span class="sourceLineNo">039</span><a id="line.39">import edu.stanford.nlp.pipeline.Annotation;</a>
<span class="sourceLineNo">040</span><a id="line.40">import edu.stanford.nlp.pipeline.AnnotationPipeline;</a>
<span class="sourceLineNo">041</span><a id="line.41">import edu.stanford.nlp.pipeline.MorphaAnnotator;</a>
<span class="sourceLineNo">042</span><a id="line.42">import edu.stanford.nlp.pipeline.NERCombinerAnnotator;</a>
<span class="sourceLineNo">043</span><a id="line.43">import edu.stanford.nlp.pipeline.POSTaggerAnnotator;</a>
<span class="sourceLineNo">044</span><a id="line.44">import edu.stanford.nlp.pipeline.TokenizerAnnotator;</a>
<span class="sourceLineNo">045</span><a id="line.45">import edu.stanford.nlp.pipeline.TokenizerAnnotator.TokenizerType;</a>
<span class="sourceLineNo">046</span><a id="line.46">import edu.stanford.nlp.pipeline.WordsToSentencesAnnotator;</a>
<span class="sourceLineNo">047</span><a id="line.47">import edu.stanford.nlp.tagger.maxent.MaxentTagger;</a>
<span class="sourceLineNo">048</span><a id="line.48">import edu.stanford.nlp.util.CoreMap;</a>
<span class="sourceLineNo">049</span><a id="line.49">import es.uvigo.esei.sing.textproc.step.AbstractProcessingStep;</a>
<span class="sourceLineNo">050</span><a id="line.50">import es.uvigo.esei.sing.textproc.step.ProcessingException;</a>
<span class="sourceLineNo">051</span><a id="line.51">import es.uvigo.esei.sing.textproc.step.corenlpentityextraction.NamedEntityDictionaryHelper.NamedEntityTerm;</a>
<span class="sourceLineNo">052</span><a id="line.52">import es.uvigo.esei.sing.textproc.step.corenlpentityextraction.NamedEntityDictionaryHelper.PropertyWithTemporaryFiles;</a>
<span class="sourceLineNo">053</span><a id="line.53">import es.uvigo.esei.sing.textproc.step.corenlpentityextraction.xml.definition.NERMappingsFileStepParameter;</a>
<span class="sourceLineNo">054</span><a id="line.54">import es.uvigo.esei.sing.textproc.step.corenlpentityextraction.xml.definition.OverwritableNERCategoriesStepParameter;</a>
<span class="sourceLineNo">055</span><a id="line.55">import es.uvigo.esei.sing.textproc.step.corenlpentityextraction.xml.definition.PropertiesFileProcessingStepParameter;</a>
<span class="sourceLineNo">056</span><a id="line.56">import es.uvigo.esei.sing.textproc.step.corenlpentityextraction.xml.definition.SeedWordsDirectoryProcessingStepParameter;</a>
<span class="sourceLineNo">057</span><a id="line.57">import es.uvigo.esei.sing.textproc.step.util.VariableHolder;</a>
<span class="sourceLineNo">058</span><a id="line.58">import es.uvigo.esei.sing.textproc.step.util.PathUtil;</a>
<span class="sourceLineNo">059</span><a id="line.59"></a>
<span class="sourceLineNo">060</span><a id="line.60">/**</a>
<span class="sourceLineNo">061</span><a id="line.61"> * Extracts new named entities from the input documents, from a seed set of</a>
<span class="sourceLineNo">062</span><a id="line.62"> * named entities, using the bootstrapped pattern-based learning algorithm</a>
<span class="sourceLineNo">063</span><a id="line.63"> * included with CoreNLP.</a>
<span class="sourceLineNo">064</span><a id="line.64"> * &lt;p&gt;</a>
<span class="sourceLineNo">065</span><a id="line.65"> * Example declaration for this step in a process definition file:</a>
<span class="sourceLineNo">066</span><a id="line.66"> * &lt;/p&gt;</a>
<span class="sourceLineNo">067</span><a id="line.67"> * &lt;pre&gt;</a>
<span class="sourceLineNo">068</span><a id="line.68"> * {@code &lt;step action="CoreNLPEntityExtraction"&gt;</a>
<span class="sourceLineNo">069</span><a id="line.69"> *      &lt;parameters&gt;</a>
<span class="sourceLineNo">070</span><a id="line.70"> *              &lt;textDocumentWithTitleTableName&gt;non_empty_submission&lt;/textDocumentWithTitleTableName&gt;</a>
<span class="sourceLineNo">071</span><a id="line.71"> *              &lt;textDocumentTableName&gt;non_empty_comment&lt;/textDocumentTableName&gt;</a>
<span class="sourceLineNo">072</span><a id="line.72"> *              &lt;cnlpee:seedWordsFilesDirectory&gt;entityextraction/dictionaries&lt;/cnlpee:seedWordsFilesDirectory&gt;</a>
<span class="sourceLineNo">073</span><a id="line.73"> *              &lt;cnlpee:nerMappingsFile&gt;entityextraction/entities.tsv&lt;/cnlpee:nerMappingsFile&gt;</a>
<span class="sourceLineNo">074</span><a id="line.74"> *              &lt;cnlpee:overwritableNerCategories&gt;CAUSE_OF_DEATH,IDEOLOGY,PERSON,ORGANIZATION&lt;/cnlpee:overwritableNerCategories&gt;</a>
<span class="sourceLineNo">075</span><a id="line.75"> *      &lt;/parameters&gt;</a>
<span class="sourceLineNo">076</span><a id="line.76"> * &lt;/step&gt;}</a>
<span class="sourceLineNo">077</span><a id="line.77"> * &lt;/pre&gt;</a>
<span class="sourceLineNo">078</span><a id="line.78"> *</a>
<span class="sourceLineNo">079</span><a id="line.79"> * @author Alejandro González García</a>
<span class="sourceLineNo">080</span><a id="line.80"> */</a>
<span class="sourceLineNo">081</span><a id="line.81">final class CoreNLPEntityExtractionProcessingStep extends AbstractProcessingStep {</a>
<span class="sourceLineNo">082</span><a id="line.82">        private static final String PROPERTIES_FILE_STEP_PARAMETER_NAME = new PropertiesFileProcessingStepParameter().getName();</a>
<span class="sourceLineNo">083</span><a id="line.83">        private static final String SEED_WORDS_DIR_STEP_PARAMETER_NAME = new SeedWordsDirectoryProcessingStepParameter().getName();</a>
<span class="sourceLineNo">084</span><a id="line.84">        private static final String NER_MAPPINGS_FILE_STEP_PARAMETER_NAME = new NERMappingsFileStepParameter().getName();</a>
<span class="sourceLineNo">085</span><a id="line.85">        private static final String OVERWRITABLE_NER_CATEGORIES_STEP_PARAMETER_NAME = new OverwritableNERCategoriesStepParameter().getName();</a>
<span class="sourceLineNo">086</span><a id="line.86"></a>
<span class="sourceLineNo">087</span><a id="line.87">        private static final Properties DEFAULT_SPIED_PROPERTIES;</a>
<span class="sourceLineNo">088</span><a id="line.88"></a>
<span class="sourceLineNo">089</span><a id="line.89">        private static final String CPU_THREADS_STRING = Integer.toString(Runtime.getRuntime().availableProcessors());</a>
<span class="sourceLineNo">090</span><a id="line.90"></a>
<span class="sourceLineNo">091</span><a id="line.91">        static {</a>
<span class="sourceLineNo">092</span><a id="line.92">                try {</a>
<span class="sourceLineNo">093</span><a id="line.93">                        DEFAULT_SPIED_PROPERTIES = new Properties();</a>
<span class="sourceLineNo">094</span><a id="line.94">                        DEFAULT_SPIED_PROPERTIES.load(</a>
<span class="sourceLineNo">095</span><a id="line.95">                                new InputStreamReader(</a>
<span class="sourceLineNo">096</span><a id="line.96">                                        CoreNLPEntityExtractionProcessingStep.class.getResourceAsStream("/default_spied_properties.properties"),</a>
<span class="sourceLineNo">097</span><a id="line.97">                                        StandardCharsets.UTF_8</a>
<span class="sourceLineNo">098</span><a id="line.98">                                )</a>
<span class="sourceLineNo">099</span><a id="line.99">                        );</a>
<span class="sourceLineNo">100</span><a id="line.100">                } catch (final IOException exc) {</a>
<span class="sourceLineNo">101</span><a id="line.101">                        throw new ExceptionInInitializerError(</a>
<span class="sourceLineNo">102</span><a id="line.102">                                "Couldn't load the default SPIED properties resource. Is the JAR of this step correctly packaged?"</a>
<span class="sourceLineNo">103</span><a id="line.103">                        );</a>
<span class="sourceLineNo">104</span><a id="line.104">                }</a>
<span class="sourceLineNo">105</span><a id="line.105">        }</a>
<span class="sourceLineNo">106</span><a id="line.106"></a>
<span class="sourceLineNo">107</span><a id="line.107">        /**</a>
<span class="sourceLineNo">108</span><a id="line.108">         * Instantiates a Stanford CoreNLP named entity extraction processing step.</a>
<span class="sourceLineNo">109</span><a id="line.109">         */</a>
<span class="sourceLineNo">110</span><a id="line.110">        CoreNLPEntityExtractionProcessingStep() {</a>
<span class="sourceLineNo">111</span><a id="line.111">                super(</a>
<span class="sourceLineNo">112</span><a id="line.112">                        // Additional mandatory and optional parameters, with their validation function</a>
<span class="sourceLineNo">113</span><a id="line.113">                        Map.of(</a>
<span class="sourceLineNo">114</span><a id="line.114">                                SEED_WORDS_DIR_STEP_PARAMETER_NAME, (final String value) -&gt; value != null &amp;&amp; !value.isBlank(),</a>
<span class="sourceLineNo">115</span><a id="line.115">                                PROPERTIES_FILE_STEP_PARAMETER_NAME, (final String value) -&gt; value != null &amp;&amp; !value.isBlank(),</a>
<span class="sourceLineNo">116</span><a id="line.116">                                NER_MAPPINGS_FILE_STEP_PARAMETER_NAME, (final String value) -&gt; value != null &amp;&amp; !value.isBlank(),</a>
<span class="sourceLineNo">117</span><a id="line.117">                                OVERWRITABLE_NER_CATEGORIES_STEP_PARAMETER_NAME, (final String value) -&gt; value != null</a>
<span class="sourceLineNo">118</span><a id="line.118">                        ),</a>
<span class="sourceLineNo">119</span><a id="line.119">                        // Additional mandatory parameters</a>
<span class="sourceLineNo">120</span><a id="line.120">                        Set.of(</a>
<span class="sourceLineNo">121</span><a id="line.121">                                SEED_WORDS_DIR_STEP_PARAMETER_NAME, NER_MAPPINGS_FILE_STEP_PARAMETER_NAME,</a>
<span class="sourceLineNo">122</span><a id="line.122">                                OVERWRITABLE_NER_CATEGORIES_STEP_PARAMETER_NAME</a>
<span class="sourceLineNo">123</span><a id="line.123">                        )</a>
<span class="sourceLineNo">124</span><a id="line.124">                );</a>
<span class="sourceLineNo">125</span><a id="line.125">        }</a>
<span class="sourceLineNo">126</span><a id="line.126"></a>
<span class="sourceLineNo">127</span><a id="line.127">        @Override</a>
<span class="sourceLineNo">128</span><a id="line.128">        protected void run() throws ProcessingException {</a>
<span class="sourceLineNo">129</span><a id="line.129">                final Object spiedLock = new Object();</a>
<span class="sourceLineNo">130</span><a id="line.130">                final VariableHolder&lt;Boolean&gt; modelGenerated = new VariableHolder&lt;&gt;(false);</a>
<span class="sourceLineNo">131</span><a id="line.131">                final List&lt;String&gt; overwritableNerCategories = ((Function&lt;List&lt;String&gt;, List&lt;String&gt;&gt;)</a>
<span class="sourceLineNo">132</span><a id="line.132">                        // A single blank overwritable category should be an empty list,</a>
<span class="sourceLineNo">133</span><a id="line.133">                        // because it means no categories to overwrite</a>
<span class="sourceLineNo">134</span><a id="line.134">                        (final List&lt;String&gt; l) -&gt; l.get(0).isBlank() ? Collections.emptyList() : l</a>
<span class="sourceLineNo">135</span><a id="line.135">                ).apply(</a>
<span class="sourceLineNo">136</span><a id="line.136">                        Arrays.asList(getParameters().get(OVERWRITABLE_NER_CATEGORIES_STEP_PARAMETER_NAME).trim().split(","))</a>
<span class="sourceLineNo">137</span><a id="line.137">                );</a>
<span class="sourceLineNo">138</span><a id="line.138"></a>
<span class="sourceLineNo">139</span><a id="line.139">                try (final PrintStream nullPrintStream = new PrintStream(OutputStream.nullOutputStream())) {</a>
<span class="sourceLineNo">140</span><a id="line.140">                        final Map&lt;String, Set&lt;NamedEntityTerm&gt;&gt; labelTerms = NamedEntityDictionaryHelper.namedEntitiesFromPathChildren(</a>
<span class="sourceLineNo">141</span><a id="line.141">                                Path.of(getParameters().get(SEED_WORDS_DIR_STEP_PARAMETER_NAME))</a>
<span class="sourceLineNo">142</span><a id="line.142">                        );</a>
<span class="sourceLineNo">143</span><a id="line.143"></a>
<span class="sourceLineNo">144</span><a id="line.144">                        try (final NERMappingsFileWriter nerMappingsWriter = new NERMappingsFileWriter(</a>
<span class="sourceLineNo">145</span><a id="line.145">                                        Path.of(getParameters().get(NER_MAPPINGS_FILE_STEP_PARAMETER_NAME))</a>
<span class="sourceLineNo">146</span><a id="line.146">                                )</a>
<span class="sourceLineNo">147</span><a id="line.147">                        ) {</a>
<span class="sourceLineNo">148</span><a id="line.148">                                final Path temporaryProcessingDirectory = Files.createTempDirectory("TP_CEES");</a>
<span class="sourceLineNo">149</span><a id="line.149">                                Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; {</a>
<span class="sourceLineNo">150</span><a id="line.150">                                        // Just in case the user interrupts us, or we never manage to reach the finally</a>
<span class="sourceLineNo">151</span><a id="line.151">                                        PathUtil.deletePathRecursively(temporaryProcessingDirectory);</a>
<span class="sourceLineNo">152</span><a id="line.152">                                }));</a>
<span class="sourceLineNo">153</span><a id="line.153"></a>
<span class="sourceLineNo">154</span><a id="line.154">                                try (final PropertyWithTemporaryFiles seedWordsFilesProperty = NamedEntityDictionaryHelper.namedEntitiesToSeedWordsFilesProperty(labelTerms)) {</a>
<span class="sourceLineNo">155</span><a id="line.155">                                        // Directory where SPIED stores learning results which should be</a>
<span class="sourceLineNo">156</span><a id="line.156">                                        // carried on from document to document</a>
<span class="sourceLineNo">157</span><a id="line.157">                                        final Path temporaryOutputDirectory = Files.createDirectory(temporaryProcessingDirectory.resolve("out"));</a>
<span class="sourceLineNo">158</span><a id="line.158">                                        final Path temporaryModelDirectory;</a>
<span class="sourceLineNo">159</span><a id="line.159"></a>
<span class="sourceLineNo">160</span><a id="line.160">                                        // With every input parsed, it is a good time to add initial NER mappings to the result file</a>
<span class="sourceLineNo">161</span><a id="line.161">                                        for (final Entry&lt;String, Set&lt;NamedEntityTerm&gt;&gt; labelTermsEntry : labelTerms.entrySet()) {</a>
<span class="sourceLineNo">162</span><a id="line.162">                                                final String label = labelTermsEntry.getKey();</a>
<span class="sourceLineNo">163</span><a id="line.163">                                                for (final NamedEntityTerm term : labelTermsEntry.getValue()) {</a>
<span class="sourceLineNo">164</span><a id="line.164">                                                        nerMappingsWriter.writeMapping(term.getTerm(), label, overwritableNerCategories);</a>
<span class="sourceLineNo">165</span><a id="line.165">                                                        for (final String synonym : term.getSynonyms()) {</a>
<span class="sourceLineNo">166</span><a id="line.166">                                                                nerMappingsWriter.writeMapping(synonym, label, overwritableNerCategories);</a>
<span class="sourceLineNo">167</span><a id="line.167">                                                        }</a>
<span class="sourceLineNo">168</span><a id="line.168">                                                }</a>
<span class="sourceLineNo">169</span><a id="line.169">                                        }</a>
<span class="sourceLineNo">170</span><a id="line.170"></a>
<span class="sourceLineNo">171</span><a id="line.171">                                        final Properties spiedProperties = new Properties();</a>
<span class="sourceLineNo">172</span><a id="line.172">                                        spiedProperties.putAll(DEFAULT_SPIED_PROPERTIES); // The default properties mechanism doesn't work with CoreNLP</a>
<span class="sourceLineNo">173</span><a id="line.173">                                        // Set a reasonable default value for numThreads</a>
<span class="sourceLineNo">174</span><a id="line.174">                                        spiedProperties.setProperty("numThreads", CPU_THREADS_STRING);</a>
<span class="sourceLineNo">175</span><a id="line.175"></a>
<span class="sourceLineNo">176</span><a id="line.176">                                        // Load custom properties, if applicable</a>
<span class="sourceLineNo">177</span><a id="line.177">                                        if (getParameters().get(PROPERTIES_FILE_STEP_PARAMETER_NAME) != null) {</a>
<span class="sourceLineNo">178</span><a id="line.178">                                                spiedProperties.load(</a>
<span class="sourceLineNo">179</span><a id="line.179">                                                        new FileReader(</a>
<span class="sourceLineNo">180</span><a id="line.180">                                                                getParameters().get(PROPERTIES_FILE_STEP_PARAMETER_NAME), StandardCharsets.UTF_8</a>
<span class="sourceLineNo">181</span><a id="line.181">                                                        )</a>
<span class="sourceLineNo">182</span><a id="line.182">                                                );</a>
<span class="sourceLineNo">183</span><a id="line.183">                                        }</a>
<span class="sourceLineNo">184</span><a id="line.184"></a>
<span class="sourceLineNo">185</span><a id="line.185">                                        spiedProperties.setProperty("seedWordsFiles", seedWordsFilesProperty.getValue());</a>
<span class="sourceLineNo">186</span><a id="line.186">                                        spiedProperties.setProperty("fileFormat", "ser"); // We generate this serialized format for performance. See below</a>
<span class="sourceLineNo">187</span><a id="line.187">                                        spiedProperties.setProperty("outDir", temporaryOutputDirectory.toRealPath().toString());</a>
<span class="sourceLineNo">188</span><a id="line.188">                                        temporaryModelDirectory = Files.createDirectories(</a>
<span class="sourceLineNo">189</span><a id="line.189">                                                temporaryProcessingDirectory.resolve(spiedProperties.getProperty("identifier")).resolve("model")</a>
<span class="sourceLineNo">190</span><a id="line.190">                                        );</a>
<span class="sourceLineNo">191</span><a id="line.191">                                        spiedProperties.setProperty(</a>
<span class="sourceLineNo">192</span><a id="line.192">                                                "patternsWordsDir",</a>
<span class="sourceLineNo">193</span><a id="line.193">                                                // Yes, appending the separator at the end is actually needed...</a>
<span class="sourceLineNo">194</span><a id="line.194">                                                // Otherwise, CoreNLP doesn't interpret the path correctly and it</a>
<span class="sourceLineNo">195</span><a id="line.195">                                                // breaks silently :)</a>
<span class="sourceLineNo">196</span><a id="line.196">                                                temporaryModelDirectory.toRealPath().toString() + File.separatorChar</a>
<span class="sourceLineNo">197</span><a id="line.197">                                        );</a>
<span class="sourceLineNo">198</span><a id="line.198"></a>
<span class="sourceLineNo">199</span><a id="line.199">                                        final Properties nerAnnotatorProperties = new Properties();</a>
<span class="sourceLineNo">200</span><a id="line.200">                                        nerAnnotatorProperties.setProperty("ner.model", spiedProperties.getProperty("nerModelPaths"));</a>
<span class="sourceLineNo">201</span><a id="line.201">                                        // Time named entities are recognized with SUTime, which needs model files.</a>
<span class="sourceLineNo">202</span><a id="line.202">                                        // We don't need to recognize time named entities, so we can disable</a>
<span class="sourceLineNo">203</span><a id="line.203">                                        // SUTime entirely</a>
<span class="sourceLineNo">204</span><a id="line.204">                                        nerAnnotatorProperties.setProperty("ner.useSUTime", Boolean.toString(false));</a>
<span class="sourceLineNo">205</span><a id="line.205">                                        nerAnnotatorProperties.setProperty("ner.applyFineGrained", spiedProperties.getProperty("applyFineGrainedRegexner"));</a>
<span class="sourceLineNo">206</span><a id="line.206">                                        nerAnnotatorProperties.setProperty("ner.fine.regexner.mapping", spiedProperties.getProperty("fineGrainedRegexnerMapping"));</a>
<span class="sourceLineNo">207</span><a id="line.207">                                        // Use all CPU threads for NER. This usually improves performance</a>
<span class="sourceLineNo">208</span><a id="line.208">                                        nerAnnotatorProperties.setProperty("ner.nthreads", CPU_THREADS_STRING);</a>
<span class="sourceLineNo">209</span><a id="line.209"></a>
<span class="sourceLineNo">210</span><a id="line.210">                                        // We have the seed words files. Now it is a good time to create the pipeline.</a>
<span class="sourceLineNo">211</span><a id="line.211">                                        // Although SPIED automatically creates a pipeline and reuses it, we can do better</a>
<span class="sourceLineNo">212</span><a id="line.212">                                        // by handling things ourselves. This minimizes overheads and gives us control of</a>
<span class="sourceLineNo">213</span><a id="line.213">                                        // temporary serialized files. See:</a>
<span class="sourceLineNo">214</span><a id="line.214">                                        // https://github.com/stanfordnlp/CoreNLP/blob/a9a4c2d75b177790a24c0f46188810668d044cd8/src/edu/stanford/nlp/patterns/GetPatternsFromDataMultiClass.java#L654</a>
<span class="sourceLineNo">215</span><a id="line.215">                                        final AnnotationPipeline nlpPipeline = new AnnotationPipeline();</a>
<span class="sourceLineNo">216</span><a id="line.216">                                        // We assume the input is already tokenized, so we use a cheap whitespace tokenizer.</a>
<span class="sourceLineNo">217</span><a id="line.217">                                        // The original code uses this property for the tokenizer:</a>
<span class="sourceLineNo">218</span><a id="line.218">                                        // props.setProperty("tokenize.options", "ptb3Escaping=false,normalizeParentheses=false,escapeForwardSlashAsterisk=false");</a>
<span class="sourceLineNo">219</span><a id="line.219">                                        nlpPipeline.addAnnotator(new TokenizerAnnotator(false, TokenizerType.Whitespace));</a>
<span class="sourceLineNo">220</span><a id="line.220">                                        // Required by SPIED</a>
<span class="sourceLineNo">221</span><a id="line.221">                                        nlpPipeline.addAnnotator(new WordsToSentencesAnnotator(false));</a>
<span class="sourceLineNo">222</span><a id="line.222">                                        // Required by SPIED</a>
<span class="sourceLineNo">223</span><a id="line.223">                                        nlpPipeline.addAnnotator(</a>
<span class="sourceLineNo">224</span><a id="line.224">                                                new POSTaggerAnnotator(</a>
<span class="sourceLineNo">225</span><a id="line.225">                                                        new MaxentTagger(spiedProperties.getProperty("posModelPath"))</a>
<span class="sourceLineNo">226</span><a id="line.226">                                                )</a>
<span class="sourceLineNo">227</span><a id="line.227">                                        );</a>
<span class="sourceLineNo">228</span><a id="line.228">                                        // Required by SPIED</a>
<span class="sourceLineNo">229</span><a id="line.229">                                        nlpPipeline.addAnnotator(new MorphaAnnotator(false));</a>
<span class="sourceLineNo">230</span><a id="line.230">                                        // Required by SPIED</a>
<span class="sourceLineNo">231</span><a id="line.231">                                        nlpPipeline.addAnnotator(new NERCombinerAnnotator(nerAnnotatorProperties));</a>
<span class="sourceLineNo">232</span><a id="line.232"></a>
<span class="sourceLineNo">233</span><a id="line.233">                                        // Pipeline ready. Time to do the extraction for each document</a>
<span class="sourceLineNo">234</span><a id="line.234">                                        for (int i = 0; i &lt; unprocessedDocumentTypesNames.size(); ++i) {</a>
<span class="sourceLineNo">235</span><a id="line.235">                                                final String[] unprocessedAttributeNames = unprocessedDocumentsAttributes.get(i);</a>
<span class="sourceLineNo">236</span><a id="line.236"></a>
<span class="sourceLineNo">237</span><a id="line.237">                                                forEachDocumentInNativeQuery(</a>
<span class="sourceLineNo">238</span><a id="line.238">                                                        unprocessedDocumentsQuerySuppliers.get(i),</a>
<span class="sourceLineNo">239</span><a id="line.239">                                                        String.format("Extracting extra NE from %s", unprocessedDocumentTypesNames.get(i)),</a>
<span class="sourceLineNo">240</span><a id="line.240">                                                        numberOfUnprocessedEntitiesProviders.get(i).get(),</a>
<span class="sourceLineNo">241</span><a id="line.241">                                                        (final List&lt;String[]&gt; batchAttributes) -&gt; {</a>
<span class="sourceLineNo">242</span><a id="line.242">                                                                int k = 0;</a>
<span class="sourceLineNo">243</span><a id="line.243">                                                                final StringBuilder concatenatedDocuments = new StringBuilder(</a>
<span class="sourceLineNo">244</span><a id="line.244">                                                                        // On average, there are 5 letters per word (+ 1 for space)</a>
<span class="sourceLineNo">245</span><a id="line.245">                                                                        6 *</a>
<span class="sourceLineNo">246</span><a id="line.246">                                                                        // Most social media posts contain 150 or less words</a>
<span class="sourceLineNo">247</span><a id="line.247">                                                                        150 *</a>
<span class="sourceLineNo">248</span><a id="line.248">                                                                        // How many posts (documents) are we processing now</a>
<span class="sourceLineNo">249</span><a id="line.249">                                                                        Integer.parseInt(</a>
<span class="sourceLineNo">250</span><a id="line.250">                                                                                getParameters().getOrDefault(</a>
<span class="sourceLineNo">251</span><a id="line.251">                                                                                        BATCH_SIZE_STEP_PARAMETER_NAME, DEFAULT_BATCH_SIZE_STEP_PARAMETER</a>
<span class="sourceLineNo">252</span><a id="line.252">                                                                                )</a>
<span class="sourceLineNo">253</span><a id="line.253">                                                                        )</a>
<span class="sourceLineNo">254</span><a id="line.254">                                                                );</a>
<span class="sourceLineNo">255</span><a id="line.255">                                                                final Map&lt;String, DataInstance&gt; sentenceMap = new HashMap&lt;&gt;();</a>
<span class="sourceLineNo">256</span><a id="line.256"></a>
<span class="sourceLineNo">257</span><a id="line.257">                                                                // Concatenate all attributes of all documents in a buffer for</a>
<span class="sourceLineNo">258</span><a id="line.258">                                                                // top efficiency</a>
<span class="sourceLineNo">259</span><a id="line.259">                                                                for (final String[] documentAttributes : batchAttributes) {</a>
<span class="sourceLineNo">260</span><a id="line.260">                                                                        for (int j = 0; j &lt; unprocessedAttributeNames.length; ++j) {</a>
<span class="sourceLineNo">261</span><a id="line.261">                                                                                if (!documentAttributes[j + 1].isBlank()) {</a>
<span class="sourceLineNo">262</span><a id="line.262">                                                                                        concatenatedDocuments.append(documentAttributes[j + 1])</a>
<span class="sourceLineNo">263</span><a id="line.263">                                                                                                .append('\n');</a>
<span class="sourceLineNo">264</span><a id="line.264">                                                                                }</a>
<span class="sourceLineNo">265</span><a id="line.265">                                                                        }</a>
<span class="sourceLineNo">266</span><a id="line.266">                                                                }</a>
<span class="sourceLineNo">267</span><a id="line.267"></a>
<span class="sourceLineNo">268</span><a id="line.268">                                                                // In the unlikely case that the resulting document is empty, ignore it</a>
<span class="sourceLineNo">269</span><a id="line.269">                                                                final String document = concatenatedDocuments.toString().strip();</a>
<span class="sourceLineNo">270</span><a id="line.270">                                                                if (document.isEmpty()) {</a>
<span class="sourceLineNo">271</span><a id="line.271">                                                                        return;</a>
<span class="sourceLineNo">272</span><a id="line.272">                                                                }</a>
<span class="sourceLineNo">273</span><a id="line.273"></a>
<span class="sourceLineNo">274</span><a id="line.274">                                                                // Now store every sentence of the concatenated documents buffer in a map.</a>
<span class="sourceLineNo">275</span><a id="line.275">                                                                // Based on https://github.com/stanfordnlp/CoreNLP/blob/a9a4c2d75b177790a24c0f46188810668d044cd8/src/edu/stanford/nlp/patterns/GetPatternsFromDataMultiClass.java#L702</a>
<span class="sourceLineNo">276</span><a id="line.276">                                                                final Annotation annotatedDocument = new Annotation(document);</a>
<span class="sourceLineNo">277</span><a id="line.277">                                                                nlpPipeline.annotate(annotatedDocument);</a>
<span class="sourceLineNo">278</span><a id="line.278">                                                                for (final CoreMap sentence : annotatedDocument.get(SentencesAnnotation.class)) {</a>
<span class="sourceLineNo">279</span><a id="line.279">                                                                        sentenceMap.put(</a>
<span class="sourceLineNo">280</span><a id="line.280">                                                                                Integer.toString(k++), // Luckily, the key value just needs to be unique</a>
<span class="sourceLineNo">281</span><a id="line.281">                                                                                DataInstance.getNewInstance(PatternFactory.PatternType.SURFACE, sentence)</a>
<span class="sourceLineNo">282</span><a id="line.282">                                                                        );</a>
<span class="sourceLineNo">283</span><a id="line.283">                                                                }</a>
<span class="sourceLineNo">284</span><a id="line.284"></a>
<span class="sourceLineNo">285</span><a id="line.285">                                                                Path temporarySentencesFile = null;</a>
<span class="sourceLineNo">286</span><a id="line.286">                                                                try {</a>
<span class="sourceLineNo">287</span><a id="line.287">                                                                        temporarySentencesFile = Files.createTempFile(</a>
<span class="sourceLineNo">288</span><a id="line.288">                                                                                temporaryProcessingDirectory, "docsents", ".ser"</a>
<span class="sourceLineNo">289</span><a id="line.289">                                                                        );</a>
<span class="sourceLineNo">290</span><a id="line.290"></a>
<span class="sourceLineNo">291</span><a id="line.291">                                                                        // Serialize the map, like IOUtils does</a>
<span class="sourceLineNo">292</span><a id="line.292">                                                                        // (but better, because this closes the file even if an exception is thrown)</a>
<span class="sourceLineNo">293</span><a id="line.293">                                                                        try (</a>
<span class="sourceLineNo">294</span><a id="line.294">                                                                                final ObjectOutputStream sentenceMapStream = new ObjectOutputStream(</a>
<span class="sourceLineNo">295</span><a id="line.295">                                                                                        Files.newOutputStream(temporarySentencesFile)</a>
<span class="sourceLineNo">296</span><a id="line.296">                                                                                )</a>
<span class="sourceLineNo">297</span><a id="line.297">                                                                        ) {</a>
<span class="sourceLineNo">298</span><a id="line.298">                                                                                sentenceMapStream.writeObject(sentenceMap);</a>
<span class="sourceLineNo">299</span><a id="line.299">                                                                        }</a>
<span class="sourceLineNo">300</span><a id="line.300"></a>
<span class="sourceLineNo">301</span><a id="line.301">                                                                        spiedProperties.setProperty("file", temporarySentencesFile.toRealPath().toString());</a>
<span class="sourceLineNo">302</span><a id="line.302"></a>
<span class="sourceLineNo">303</span><a id="line.303">                                                                        // SPIED has to be executed serially, because each run for each document attribute</a>
<span class="sourceLineNo">304</span><a id="line.304">                                                                        // updates the model, and the model isn't supposed to be read and updated concurrently.</a>
<span class="sourceLineNo">305</span><a id="line.305">                                                                        // However, the numThreads property allows to parallelize the actual entity extraction</a>
<span class="sourceLineNo">306</span><a id="line.306">                                                                        // process, which is the time consuming thing here</a>
<span class="sourceLineNo">307</span><a id="line.307">                                                                        final List&lt;Entry&lt;String, Path&gt;&gt; learnedWordsFiles = new ArrayList&lt;&gt;();</a>
<span class="sourceLineNo">308</span><a id="line.308">                                                                        synchronized (spiedLock) {</a>
<span class="sourceLineNo">309</span><a id="line.309">                                                                                spiedProperties.setProperty("loadSavedPatternsWordsDir", modelGenerated.getVariable().toString());</a>
<span class="sourceLineNo">310</span><a id="line.310"></a>
<span class="sourceLineNo">311</span><a id="line.311">                                                                                final PrintStream stdout = System.out;</a>
<span class="sourceLineNo">312</span><a id="line.312">                                                                                final PrintStream stderr = System.err;</a>
<span class="sourceLineNo">313</span><a id="line.313">                                                                                try {</a>
<span class="sourceLineNo">314</span><a id="line.314">                                                                                        // SPIED pollutes standard output no matter what.</a>
<span class="sourceLineNo">315</span><a id="line.315">                                                                                        // Avoid that by reassigning the output streams temporarily</a>
<span class="sourceLineNo">316</span><a id="line.316">                                                                                        System.setOut(nullPrintStream);</a>
<span class="sourceLineNo">317</span><a id="line.317">                                                                                        System.setErr(nullPrintStream);</a>
<span class="sourceLineNo">318</span><a id="line.318"></a>
<span class="sourceLineNo">319</span><a id="line.319">                                                                                        GetPatternsFromDataMultiClass.&lt;SurfacePattern&gt;run(spiedProperties);</a>
<span class="sourceLineNo">320</span><a id="line.320">                                                                                } finally {</a>
<span class="sourceLineNo">321</span><a id="line.321">                                                                                        System.setOut(stdout);</a>
<span class="sourceLineNo">322</span><a id="line.322">                                                                                        System.setErr(stderr);</a>
<span class="sourceLineNo">323</span><a id="line.323">                                                                                }</a>
<span class="sourceLineNo">324</span><a id="line.324"></a>
<span class="sourceLineNo">325</span><a id="line.325">                                                                                modelGenerated.setVariable(true);</a>
<span class="sourceLineNo">326</span><a id="line.326"></a>
<span class="sourceLineNo">327</span><a id="line.327">                                                                                // SPIED stores the learned words here:</a>
<span class="sourceLineNo">328</span><a id="line.328">                                                                                // ${temporaryOutputDirectory}/${identifier}/${label}/learnedwords.txt</a>
<span class="sourceLineNo">329</span><a id="line.329">                                                                                // These files are overwritten between runs, so their contents need to</a>
<span class="sourceLineNo">330</span><a id="line.330">                                                                                // be copied elsewhere. The resulting NER mapping file is the ideal place,</a>
<span class="sourceLineNo">331</span><a id="line.331">                                                                                // but we are in a critical section here, so copy the files to another path</a>
<span class="sourceLineNo">332</span><a id="line.332">                                                                                // and process them later</a>
<span class="sourceLineNo">333</span><a id="line.333">                                                                                for (final String label : labelTerms.keySet()) {</a>
<span class="sourceLineNo">334</span><a id="line.334">                                                                                        learnedWordsFiles.add(new SimpleImmutableEntry&lt;&gt;(label,</a>
<span class="sourceLineNo">335</span><a id="line.335">                                                                                                Files.copy(</a>
<span class="sourceLineNo">336</span><a id="line.336">                                                                                                        temporaryOutputDirectory</a>
<span class="sourceLineNo">337</span><a id="line.337">                                                                                                                .resolve(spiedProperties.getProperty("identifier"))</a>
<span class="sourceLineNo">338</span><a id="line.338">                                                                                                                .resolve(label)</a>
<span class="sourceLineNo">339</span><a id="line.339">                                                                                                                .resolve("learnedwords.txt"),</a>
<span class="sourceLineNo">340</span><a id="line.340">                                                                                                        Files.createTempFile(</a>
<span class="sourceLineNo">341</span><a id="line.341">                                                                                                                temporaryProcessingDirectory, "learnedwords", ".txt"</a>
<span class="sourceLineNo">342</span><a id="line.342">                                                                                                        ),</a>
<span class="sourceLineNo">343</span><a id="line.343">                                                                                                        StandardCopyOption.REPLACE_EXISTING, StandardCopyOption.COPY_ATTRIBUTES</a>
<span class="sourceLineNo">344</span><a id="line.344">                                                                                                )</a>
<span class="sourceLineNo">345</span><a id="line.345">                                                                                        ));</a>
<span class="sourceLineNo">346</span><a id="line.346">                                                                                }</a>
<span class="sourceLineNo">347</span><a id="line.347">                                                                        }</a>
<span class="sourceLineNo">348</span><a id="line.348"></a>
<span class="sourceLineNo">349</span><a id="line.349">                                                                        // We are out of the critical section now.</a>
<span class="sourceLineNo">350</span><a id="line.350">                                                                        // Add the learned words to the mapping file with the least contention possible</a>
<span class="sourceLineNo">351</span><a id="line.351">                                                                        for (final Entry&lt;String, Path&gt; learnedWordsFile : learnedWordsFiles) {</a>
<span class="sourceLineNo">352</span><a id="line.352">                                                                                final String label = learnedWordsFile.getKey();</a>
<span class="sourceLineNo">353</span><a id="line.353"></a>
<span class="sourceLineNo">354</span><a id="line.354">                                                                                try (final BufferedReader reader = new BufferedReader(</a>
<span class="sourceLineNo">355</span><a id="line.355">                                                                                        new InputStreamReader(</a>
<span class="sourceLineNo">356</span><a id="line.356">                                                                                                Files.newInputStream(</a>
<span class="sourceLineNo">357</span><a id="line.357">                                                                                                        learnedWordsFile.getValue(), StandardOpenOption.DELETE_ON_CLOSE</a>
<span class="sourceLineNo">358</span><a id="line.358">                                                                                                ), StandardCharsets.UTF_8</a>
<span class="sourceLineNo">359</span><a id="line.359">                                                                                        )</a>
<span class="sourceLineNo">360</span><a id="line.360">                                                                                )) {</a>
<span class="sourceLineNo">361</span><a id="line.361">                                                                                        String word;</a>
<span class="sourceLineNo">362</span><a id="line.362">                                                                                        while ((word = reader.readLine()) != null) {</a>
<span class="sourceLineNo">363</span><a id="line.363">                                                                                                if (!word.isBlank()) {</a>
<span class="sourceLineNo">364</span><a id="line.364">                                                                                                        nerMappingsWriter.writeMapping(word, label, overwritableNerCategories);</a>
<span class="sourceLineNo">365</span><a id="line.365">                                                                                                }</a>
<span class="sourceLineNo">366</span><a id="line.366">                                                                                        }</a>
<span class="sourceLineNo">367</span><a id="line.367">                                                                                }</a>
<span class="sourceLineNo">368</span><a id="line.368">                                                                        }</a>
<span class="sourceLineNo">369</span><a id="line.369">                                                                } catch (</a>
<span class="sourceLineNo">370</span><a id="line.370">                                                                        final IOException | ReflectiveOperationException |</a>
<span class="sourceLineNo">371</span><a id="line.371">                                                                        InterruptedException | ExecutionException | SQLException exc</a>
<span class="sourceLineNo">372</span><a id="line.372">                                                                ) {</a>
<span class="sourceLineNo">373</span><a id="line.373">                                                                        throw new ProcessingException(DATA_ACCESS_EXCEPTION_MESSAGE, exc);</a>
<span class="sourceLineNo">374</span><a id="line.374">                                                                } finally {</a>
<span class="sourceLineNo">375</span><a id="line.375">                                                                        // Clean up the current temporary sentences file</a>
<span class="sourceLineNo">376</span><a id="line.376">                                                                        if (temporarySentencesFile != null) {</a>
<span class="sourceLineNo">377</span><a id="line.377">                                                                                try {</a>
<span class="sourceLineNo">378</span><a id="line.378">                                                                                        Files.deleteIfExists(temporarySentencesFile);</a>
<span class="sourceLineNo">379</span><a id="line.379">                                                                                } catch (final IOException ignored) {}</a>
<span class="sourceLineNo">380</span><a id="line.380">                                                                        }</a>
<span class="sourceLineNo">381</span><a id="line.381">                                                                }</a>
<span class="sourceLineNo">382</span><a id="line.382">                                                        },</a>
<span class="sourceLineNo">383</span><a id="line.383">                                                        null</a>
<span class="sourceLineNo">384</span><a id="line.384">                                                );</a>
<span class="sourceLineNo">385</span><a id="line.385">                                        }</a>
<span class="sourceLineNo">386</span><a id="line.386">                                } finally {</a>
<span class="sourceLineNo">387</span><a id="line.387">                                        // Remove temporary files directory</a>
<span class="sourceLineNo">388</span><a id="line.388">                                        PathUtil.deletePathRecursively(temporaryProcessingDirectory);</a>
<span class="sourceLineNo">389</span><a id="line.389">                                }</a>
<span class="sourceLineNo">390</span><a id="line.390">                        }</a>
<span class="sourceLineNo">391</span><a id="line.391">                } catch (final IOException | IllegalArgumentException | PersistenceException exc) {</a>
<span class="sourceLineNo">392</span><a id="line.392">                        throw new ProcessingException(DATA_ACCESS_EXCEPTION_MESSAGE, exc);</a>
<span class="sourceLineNo">393</span><a id="line.393">                }</a>
<span class="sourceLineNo">394</span><a id="line.394">        }</a>
<span class="sourceLineNo">395</span><a id="line.395">}</a>




























































</pre>
</div>
</main>
</body>
</html>
