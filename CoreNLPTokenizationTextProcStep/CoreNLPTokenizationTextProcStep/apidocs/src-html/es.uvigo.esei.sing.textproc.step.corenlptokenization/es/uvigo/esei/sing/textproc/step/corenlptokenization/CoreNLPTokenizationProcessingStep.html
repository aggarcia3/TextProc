<!DOCTYPE HTML>
<html lang="es">
<head>
<!-- Generated by javadoc -->
<title>Source code</title>
<meta name="description" content="source: module: es.uvigo.esei.sing.textproc.step.corenlptokenization, package: es.uvigo.esei.sing.textproc.step.corenlptokenization, class: CoreNLPTokenizationProcessingStep">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../../../../../stylesheet.css" title="Style">
</head>
<body class="source">
<main role="main">
<div class="sourceContainer">
<pre><span class="sourceLineNo">001</span><a id="line.1">// SPDX-License-Identifier: GPL-3.0-or-later</a>
<span class="sourceLineNo">002</span><a id="line.2"></a>
<span class="sourceLineNo">003</span><a id="line.3">package es.uvigo.esei.sing.textproc.step.corenlptokenization;</a>
<span class="sourceLineNo">004</span><a id="line.4"></a>
<span class="sourceLineNo">005</span><a id="line.5">import java.util.Collections;</a>
<span class="sourceLineNo">006</span><a id="line.6">import java.util.HashMap;</a>
<span class="sourceLineNo">007</span><a id="line.7">import java.util.List;</a>
<span class="sourceLineNo">008</span><a id="line.8">import java.util.Map;</a>
<span class="sourceLineNo">009</span><a id="line.9">import java.util.Set;</a>
<span class="sourceLineNo">010</span><a id="line.10"></a>
<span class="sourceLineNo">011</span><a id="line.11">import javax.persistence.PersistenceException;</a>
<span class="sourceLineNo">012</span><a id="line.12"></a>
<span class="sourceLineNo">013</span><a id="line.13">import edu.stanford.nlp.ling.CoreAnnotations.TextAnnotation;</a>
<span class="sourceLineNo">014</span><a id="line.14">import edu.stanford.nlp.ling.CoreAnnotations.TokensAnnotation;</a>
<span class="sourceLineNo">015</span><a id="line.15">import edu.stanford.nlp.ling.CoreLabel;</a>
<span class="sourceLineNo">016</span><a id="line.16">import edu.stanford.nlp.pipeline.Annotation;</a>
<span class="sourceLineNo">017</span><a id="line.17">import edu.stanford.nlp.pipeline.AnnotationPipeline;</a>
<span class="sourceLineNo">018</span><a id="line.18">import edu.stanford.nlp.pipeline.TokenizerAnnotator;</a>
<span class="sourceLineNo">019</span><a id="line.19">import es.uvigo.esei.sing.textproc.entity.ProcessedDocument;</a>
<span class="sourceLineNo">020</span><a id="line.20">import es.uvigo.esei.sing.textproc.step.AbstractProcessingStep;</a>
<span class="sourceLineNo">021</span><a id="line.21">import es.uvigo.esei.sing.textproc.step.ProcessingException;</a>
<span class="sourceLineNo">022</span><a id="line.22">import es.uvigo.esei.sing.textproc.step.corenlptokenization.entity.CoreNLPTokenizedTextDocument;</a>
<span class="sourceLineNo">023</span><a id="line.23">import es.uvigo.esei.sing.textproc.step.corenlptokenization.entity.CoreNLPTokenizedTextWithTitleDocument;</a>
<span class="sourceLineNo">024</span><a id="line.24">import es.uvigo.esei.sing.textproc.step.corenlptokenization.xml.definition.LanguageProcessingStepParameter;</a>
<span class="sourceLineNo">025</span><a id="line.25">import es.uvigo.esei.sing.textproc.step.corenlptokenization.xml.definition.TokenizerOptionsProcessingStepParameter;</a>
<span class="sourceLineNo">026</span><a id="line.26"></a>
<span class="sourceLineNo">027</span><a id="line.27">/**</a>
<span class="sourceLineNo">028</span><a id="line.28"> * Tokenizes documents, according to the provided parameters, using Stanford</a>
<span class="sourceLineNo">029</span><a id="line.29"> * CoreNLP.</a>
<span class="sourceLineNo">030</span><a id="line.30"> * &lt;p&gt;</a>
<span class="sourceLineNo">031</span><a id="line.31"> * Example declaration for this step in a process definition file:</a>
<span class="sourceLineNo">032</span><a id="line.32"> * &lt;/p&gt;</a>
<span class="sourceLineNo">033</span><a id="line.33"> * &lt;pre&gt;</a>
<span class="sourceLineNo">034</span><a id="line.34"> * {@code &lt;step action="CoreNLPTokenization"&gt;</a>
<span class="sourceLineNo">035</span><a id="line.35"> *      &lt;parameters&gt;</a>
<span class="sourceLineNo">036</span><a id="line.36"> *              &lt;textDocumentWithTitleTableName&gt;submission&lt;/textDocumentWithTitleTableName&gt;</a>
<span class="sourceLineNo">037</span><a id="line.37"> *              &lt;textDocumentTableName&gt;comment&lt;/textDocumentTableName&gt;</a>
<span class="sourceLineNo">038</span><a id="line.38"> *              &lt;cnlpt:language&gt;en&lt;/cnlpt:language&gt;</a>
<span class="sourceLineNo">039</span><a id="line.39"> *      &lt;/parameters&gt;</a>
<span class="sourceLineNo">040</span><a id="line.40"> * &lt;/step&gt;}</a>
<span class="sourceLineNo">041</span><a id="line.41"> * &lt;/pre&gt;</a>
<span class="sourceLineNo">042</span><a id="line.42"> *</a>
<span class="sourceLineNo">043</span><a id="line.43"> * @author Alejandro González García</a>
<span class="sourceLineNo">044</span><a id="line.44"> */</a>
<span class="sourceLineNo">045</span><a id="line.45">final class CoreNLPTokenizationProcessingStep extends AbstractProcessingStep {</a>
<span class="sourceLineNo">046</span><a id="line.46">        private static final String LANGUAGE_PROCESSING_STEP_PARAMETER_NAME = new LanguageProcessingStepParameter().getName();</a>
<span class="sourceLineNo">047</span><a id="line.47">        private static final String TOKENIZER_OPTIONS_PROCESSING_STEP_PARAMETER_NAME = new TokenizerOptionsProcessingStepParameter().getName();</a>
<span class="sourceLineNo">048</span><a id="line.48"></a>
<span class="sourceLineNo">049</span><a id="line.49">        /**</a>
<span class="sourceLineNo">050</span><a id="line.50">         * Instantiates a Stanford CoreNLP tokenization processing step.</a>
<span class="sourceLineNo">051</span><a id="line.51">         */</a>
<span class="sourceLineNo">052</span><a id="line.52">        CoreNLPTokenizationProcessingStep() {</a>
<span class="sourceLineNo">053</span><a id="line.53">                super(</a>
<span class="sourceLineNo">054</span><a id="line.54">                        // Additional mandatory and optional parameters, with their validation function</a>
<span class="sourceLineNo">055</span><a id="line.55">                        Map.of(</a>
<span class="sourceLineNo">056</span><a id="line.56">                                LANGUAGE_PROCESSING_STEP_PARAMETER_NAME, (final String value) -&gt; value != null &amp;&amp; !value.isBlank(),</a>
<span class="sourceLineNo">057</span><a id="line.57">                                TOKENIZER_OPTIONS_PROCESSING_STEP_PARAMETER_NAME, (final String value) -&gt; value != null &amp;&amp; !value.isBlank()</a>
<span class="sourceLineNo">058</span><a id="line.58">                        ),</a>
<span class="sourceLineNo">059</span><a id="line.59">                        // Additional mandatory parameters</a>
<span class="sourceLineNo">060</span><a id="line.60">                        Set.of(LANGUAGE_PROCESSING_STEP_PARAMETER_NAME)</a>
<span class="sourceLineNo">061</span><a id="line.61">                );</a>
<span class="sourceLineNo">062</span><a id="line.62">        }</a>
<span class="sourceLineNo">063</span><a id="line.63"></a>
<span class="sourceLineNo">064</span><a id="line.64">        @Override</a>
<span class="sourceLineNo">065</span><a id="line.65">        protected void run() throws ProcessingException {</a>
<span class="sourceLineNo">066</span><a id="line.66">                final List&lt;Class&lt;? extends ProcessedDocument&gt;&gt; processedDocumentTypes = List.of(</a>
<span class="sourceLineNo">067</span><a id="line.67">                        CoreNLPTokenizedTextWithTitleDocument.class, CoreNLPTokenizedTextDocument.class</a>
<span class="sourceLineNo">068</span><a id="line.68">                );</a>
<span class="sourceLineNo">069</span><a id="line.69"></a>
<span class="sourceLineNo">070</span><a id="line.70">                final AnnotationPipeline nlpPipeline = new AnnotationPipeline();</a>
<span class="sourceLineNo">071</span><a id="line.71">                nlpPipeline.addAnnotator(</a>
<span class="sourceLineNo">072</span><a id="line.72">                        new TokenizerAnnotator(</a>
<span class="sourceLineNo">073</span><a id="line.73">                                false,</a>
<span class="sourceLineNo">074</span><a id="line.74">                                getParameters().get(LANGUAGE_PROCESSING_STEP_PARAMETER_NAME),</a>
<span class="sourceLineNo">075</span><a id="line.75">                                getParameters().getOrDefault(TOKENIZER_OPTIONS_PROCESSING_STEP_PARAMETER_NAME, "quotes=ascii")</a>
<span class="sourceLineNo">076</span><a id="line.76">                        )</a>
<span class="sourceLineNo">077</span><a id="line.77">                );</a>
<span class="sourceLineNo">078</span><a id="line.78"></a>
<span class="sourceLineNo">079</span><a id="line.79">                try {</a>
<span class="sourceLineNo">080</span><a id="line.80">                        // Delete previous results</a>
<span class="sourceLineNo">081</span><a id="line.81">                        for (final Class&lt;? extends ProcessedDocument&gt; processedDocumentType : processedDocumentTypes) {</a>
<span class="sourceLineNo">082</span><a id="line.82">                                deleteAllProcessedDocumentsOfType(processedDocumentType);</a>
<span class="sourceLineNo">083</span><a id="line.83">                        }</a>
<span class="sourceLineNo">084</span><a id="line.84"></a>
<span class="sourceLineNo">085</span><a id="line.85">                        for (int i = 0; i &lt; processedDocumentTypes.size(); ++i) {</a>
<span class="sourceLineNo">086</span><a id="line.86">                                final String[] unprocessedAttributeNames = unprocessedDocumentsAttributes.get(i);</a>
<span class="sourceLineNo">087</span><a id="line.87">                                final Class&lt;? extends ProcessedDocument&gt; processedDocumentType = processedDocumentTypes.get(i);</a>
<span class="sourceLineNo">088</span><a id="line.88"></a>
<span class="sourceLineNo">089</span><a id="line.89">                                forEachDocumentInNativeQuery(</a>
<span class="sourceLineNo">090</span><a id="line.90">                                        unprocessedDocumentsQuerySuppliers.get(i),</a>
<span class="sourceLineNo">091</span><a id="line.91">                                        String.format("Tokenizing %s", unprocessedDocumentTypesNames.get(i)),</a>
<span class="sourceLineNo">092</span><a id="line.92">                                        numberOfUnprocessedEntitiesProviders.get(i).get(),</a>
<span class="sourceLineNo">093</span><a id="line.93">                                        (final List&lt;String[]&gt; batchAttributes) -&gt; {</a>
<span class="sourceLineNo">094</span><a id="line.94">                                                final Map&lt;String, String&gt; processedAttributesMap = new HashMap&lt;&gt;(</a>
<span class="sourceLineNo">095</span><a id="line.95">                                                        (int) Math.ceil(unprocessedAttributeNames.length / 0.75)</a>
<span class="sourceLineNo">096</span><a id="line.96">                                                );</a>
<span class="sourceLineNo">097</span><a id="line.97">                                                final StringBuilder tokenizedAttribute = new StringBuilder();</a>
<span class="sourceLineNo">098</span><a id="line.98"></a>
<span class="sourceLineNo">099</span><a id="line.99">                                                for (final String[] documentAttributes : batchAttributes) {</a>
<span class="sourceLineNo">100</span><a id="line.100">                                                        for (int j = 0; j &lt; unprocessedAttributeNames.length; ++j) {</a>
<span class="sourceLineNo">101</span><a id="line.101">                                                                final Annotation annotatedAttribute = new Annotation(documentAttributes[j + 1]);</a>
<span class="sourceLineNo">102</span><a id="line.102"></a>
<span class="sourceLineNo">103</span><a id="line.103">                                                                nlpPipeline.annotate(annotatedAttribute);</a>
<span class="sourceLineNo">104</span><a id="line.104">                                                                for (final CoreLabel token : annotatedAttribute.get(TokensAnnotation.class)) {</a>
<span class="sourceLineNo">105</span><a id="line.105">                                                                        tokenizedAttribute</a>
<span class="sourceLineNo">106</span><a id="line.106">                                                                                .append(token.get(TextAnnotation.class))</a>
<span class="sourceLineNo">107</span><a id="line.107">                                                                                .append(' ');</a>
<span class="sourceLineNo">108</span><a id="line.108">                                                                }</a>
<span class="sourceLineNo">109</span><a id="line.109"></a>
<span class="sourceLineNo">110</span><a id="line.110">                                                                // Remove trailing space</a>
<span class="sourceLineNo">111</span><a id="line.111">                                                                if (tokenizedAttribute.length() &gt; 0) {</a>
<span class="sourceLineNo">112</span><a id="line.112">                                                                        tokenizedAttribute.deleteCharAt(tokenizedAttribute.length() - 1);</a>
<span class="sourceLineNo">113</span><a id="line.113">                                                                }</a>
<span class="sourceLineNo">114</span><a id="line.114"></a>
<span class="sourceLineNo">115</span><a id="line.115">                                                                processedAttributesMap.put(unprocessedAttributeNames[j], tokenizedAttribute.toString());</a>
<span class="sourceLineNo">116</span><a id="line.116"></a>
<span class="sourceLineNo">117</span><a id="line.117">                                                                // Reuse string builder buffer</a>
<span class="sourceLineNo">118</span><a id="line.118">                                                                tokenizedAttribute.setLength(0);</a>
<span class="sourceLineNo">119</span><a id="line.119">                                                        }</a>
<span class="sourceLineNo">120</span><a id="line.120"></a>
<span class="sourceLineNo">121</span><a id="line.121">                                                        saveProcessedDocument(</a>
<span class="sourceLineNo">122</span><a id="line.122">                                                                processedDocumentType, Integer.parseInt(documentAttributes[0]),</a>
<span class="sourceLineNo">123</span><a id="line.123">                                                                Collections.unmodifiableMap(processedAttributesMap)</a>
<span class="sourceLineNo">124</span><a id="line.124">                                                        );</a>
<span class="sourceLineNo">125</span><a id="line.125">                                                }</a>
<span class="sourceLineNo">126</span><a id="line.126">                                        },</a>
<span class="sourceLineNo">127</span><a id="line.127">                                        null</a>
<span class="sourceLineNo">128</span><a id="line.128">                                );</a>
<span class="sourceLineNo">129</span><a id="line.129">                        }</a>
<span class="sourceLineNo">130</span><a id="line.130">                } catch (final IllegalArgumentException | PersistenceException exc) {</a>
<span class="sourceLineNo">131</span><a id="line.131">                        throw new ProcessingException(DATA_ACCESS_EXCEPTION_MESSAGE, exc);</a>
<span class="sourceLineNo">132</span><a id="line.132">                }</a>
<span class="sourceLineNo">133</span><a id="line.133">        }</a>
<span class="sourceLineNo">134</span><a id="line.134">}</a>




























































</pre>
</div>
</main>
</body>
</html>
